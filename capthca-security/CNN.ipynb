{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d66f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "import time\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c6cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/denniscimorosi/Desktop/Tesi/Logos/\"\n",
    "states_path = PATH + \"states.csv\"\n",
    "union_path = PATH + \"union/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c48c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = pd.read_csv(states_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641bbb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f56d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogoStates(Dataset):\n",
    "    def __init__(self, states_df, transform=None,name=''):\n",
    "        self.states_df = states_df\n",
    "        \n",
    "        name = name\n",
    "        if name != '':\n",
    "            self.states_df = self.states_df[self.states_df[\"captcha\"].str.contains(name)]\n",
    "            \n",
    "        self.transform = transform\n",
    "        self.to_pil = transforms.ToPILImage()       \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.states_df)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        row = self.states_df.iloc[item]\n",
    "        captcha, label = row\n",
    "        \n",
    "        captcha_img = Image.open(union_path + captcha)\n",
    "        captcha_img = np.asarray(captcha_img)\n",
    "        captcha_img = cv2.resize(captcha_img, (28,28), interpolation=cv2.INTER_LINEAR)\n",
    "        captcha_img = PIL.Image.fromarray(captcha_img)\n",
    "        \n",
    "        # 0 se sono uguali 1 se sono diverse (invertito)\n",
    "        label = 1 if label else 0\n",
    "        \n",
    "        if self.transform:\n",
    "            captcha_img = self.transform(captcha_img)\n",
    "\n",
    "        return captcha_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40abf130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 30, 3800)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unseen: estraggo tutti i nomi, shuffle e prendo circa il 15%\n",
    "n_unseen = 3800\n",
    "unseen_df = states_df.sort_values(['captcha'])[:n_unseen]\n",
    "states_df = states_df.sort_values(['captcha'])[n_unseen:]\n",
    "\n",
    "percentage = round(len(states_df)*15/100)\n",
    "\n",
    "\n",
    "\n",
    "states_df = states_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_df = states_df[percentage:]\n",
    "test_df = states_df[:percentage]\n",
    "\n",
    "\n",
    "len(train_df), len(test_df), len(unseen_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "761bc377",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "                    transforms.Grayscale(),\n",
    "                    transforms.ToTensor()\n",
    "                 ])\n",
    "train_ds = LogoStates(train_df, transform,name='')\n",
    "test_ds = LogoStates(test_df, transform)\n",
    "unseen_ds = LogoStates(unseen_df, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbf5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, \n",
    "                    multiprocessing_context=\"fork\", num_workers=8)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=True,\n",
    "                    multiprocessing_context=\"fork\", num_workers=8)\n",
    "\n",
    "unseen_loader = DataLoader(unseen_ds, batch_size=3600, shuffle=True,\n",
    "                    multiprocessing_context=\"fork\", num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce16c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some helper functions\n",
    "def imshow(img, text=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "        \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "655be935",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37618f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN()\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.Adam(net.parameters(), lr = lr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dacfff1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4c9aa26d4e46db8ac0ef0a0f08800e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 14, 14])\n",
      "Epoch number 0\n",
      " Current loss 0.6856688261032104\n",
      "\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([10, 16, 14, 14])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 14, 14])\n",
      "Epoch number 1\n",
      " Current loss 0.6443893313407898\n",
      "\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([10, 16, 14, 14])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 14, 14])\n",
      "Epoch number 2\n",
      " Current loss 0.6196069121360779\n",
      "\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([10, 16, 14, 14])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 14, 14])\n",
      "Epoch number 3\n",
      " Current loss 0.5533661246299744\n",
      "\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([10, 16, 14, 14])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 14, 14])\n",
      "Epoch number 4\n",
      " Current loss 0.5192309021949768\n",
      "\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([10, 16, 14, 14])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 14, 14])\n",
      "Epoch number 5\n",
      " Current loss 0.5728322863578796\n",
      "\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([10, 16, 14, 14])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 14, 14])\n",
      "Epoch number 6\n",
      " Current loss 0.46348005533218384\n",
      "\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([10, 16, 14, 14])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 14, 14])\n",
      "Epoch number 7\n",
      " Current loss 0.39241698384284973\n",
      "\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([10, 16, 14, 14])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 14, 14])\n",
      "Epoch number 8\n",
      " Current loss 0.29793408513069153\n",
      "\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([10, 16, 14, 14])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 14, 14])\n",
      "Epoch number 9\n",
      " Current loss 0.2525580823421478\n",
      "\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([32, 16, 14, 14])\n",
      "torch.Size([10, 16, 14, 14])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "# Iterate throught the epochs\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i, (img, label) in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Pass in the two images into the network and obtain two outputs\n",
    "        output = net(img)\n",
    "\n",
    "        # Pass the outputs of the networks and label into the loss function\n",
    "        loss = criterion(output,label)\n",
    "\n",
    "        # Calculate the backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Every 10 batches print out the loss\n",
    "        if i % 5000 == 0 :\n",
    "            print(f\"Epoch number {epoch}\\n Current loss {loss.item()}\\n\")\n",
    "            iteration_number += 5000\n",
    "\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss.item())\n",
    "\n",
    "show_plot(counter, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c96bd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3600, 16, 14, 14])\n",
      "torch.Size([200, 16, 14, 14])\n",
      "Test Accuracy of the model on the test images: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in unseen_loader:\n",
    "        test_output = net(images)\n",
    "        pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "        #print(test_output, pred_y)\n",
    "        accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "print('Test Accuracy of the model on the test images: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f859324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 16, 14, 14])\n",
      "Test Accuracy of the model on the test images: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        test_output = net(images)\n",
    "        pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "        #print(test_output, pred_y)\n",
    "        accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "print('Test Accuracy of the model on the test images: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eab39935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(net.state_dict(), 'model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
